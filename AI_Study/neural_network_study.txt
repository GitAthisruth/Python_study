The Mathematics of Neural Networks

 - A rigorous introduction to the mathematics of networks and backpropagation.


Derivatives - They are functions to get the rates of change of y w.r.t x / slope of the tangent line

Integration - finding the area under the curve

Derivatives and Integration are opposite to each other.


Five Concepts in Calculus



    1. Function Notation
    2. Linear Function
    3. Exponents
        - Rational Exponents
        - 
    4. Domain Range
        Interval vs Set Notation

    Interval Notation               Set Notation

    ( ) -> not inclusive             > , < 
    [ ] -> inclusive                 >= , <= 
    infinity, - infinity - They
    are always not inclusive.eg -  (-infinity,4]

    5. Composite Functions
        eg: f(g(x))


slope = m = rise/run = y2 - y1 / x2 - x1


Differentiation - Gradient of curve

- If we can use infinitely small columns to find area of anything.

- Uphill - positive slope
- Downhill - negative slope

- The slope of a non-linear function is different at different points along the function. The slope may be positive, negative or zero as indicated by the tangent lines in the following chart. The value obtained for the slope depends on the point on the function where the tangent line is drawn.

- Slope of a straight line is always same.









    

